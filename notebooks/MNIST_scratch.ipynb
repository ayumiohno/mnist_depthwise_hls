{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77259cf2-0fd7-4d4e-a5be-2c54ec04180a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6244f1c9-a3fc-425e-840d-d18405bc39c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "params = json.load(open('assets/params.json'))\n",
    "conv1_depthwise = torch.tensor(params[\"conv1_depthwise\"])\n",
    "conv1_pointwise = torch.tensor(params[\"conv1_pointwise\"])\n",
    "conv2_depthwise = torch.tensor(params[\"conv2_depthwise\"])\n",
    "conv2_pointwise = torch.tensor(params[\"conv2_pointwise\"])\n",
    "conv3_depthwise = torch.tensor(params[\"conv3_depthwise\"])\n",
    "conv3_pointwise = torch.tensor(params[\"conv3_pointwise\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "396733c3-2c46-41ee-9cdd-13c67b821b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "images = json.load(open(\"assets/images_py.json\"))\n",
    "labels = json.load(open(\"assets/labels.json\"))\n",
    "images_t = []\n",
    "for image in images:\n",
    "    images_t.append(torch.tensor(image).view(28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "368b51d8-ee0a-4905-9d23-22247b8e0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointwise(x, weight, size, in_ch, out_ch):\n",
    "  # store weight to local buffer\n",
    "  out = torch.zeros(size, size, out_ch)\n",
    "  for py in range(size):\n",
    "    for px in range(size):\n",
    "      for kp in range(in_ch):\n",
    "        read = x[py, px, kp] # stream in\n",
    "        for l in range(out_ch):\n",
    "            out[py, px, l] += read * weight[l, kp]\n",
    "      for l in range(out_ch):\n",
    "        if out[py, px, l] < 0:\n",
    "          out[py, px, l] = 0\n",
    "        # stream out\n",
    "  return out\n",
    "\n",
    "def depthwise(x, weight, size, in_ch):\n",
    "  next_size = (size+2)//3\n",
    "  out = torch.zeros(next_size, next_size, in_ch)\n",
    "  x_pad = torch.zeros(size+2, size+2, in_ch)\n",
    "  x_pad[1:size+1, 1:size+1, :] = x\n",
    "  for py in range(next_size):\n",
    "    for px in range(next_size):\n",
    "      for l in range(in_ch):\n",
    "        val = 0\n",
    "        for ky in range(3):\n",
    "          for kx in range(3):\n",
    "            val += x_pad[py * 3 + ky, px * 3 + kx, l] * weight[l, ky, kx]\n",
    "        out[py, px, l] = val\n",
    "  return out\n",
    "\n",
    "def depthwise_final(x, weight, size=4, in_ch=16):\n",
    "  # store x, weight to local buffer\n",
    "  next_size = size // 4\n",
    "  out = torch.zeros(next_size, next_size, in_ch)\n",
    "  for l in range(in_ch):\n",
    "    val = 0\n",
    "    for ky in range(4):\n",
    "      for kx in range(4):\n",
    "        val += x[ky, kx, l] * weight[l, ky, kx]\n",
    "    out[0, 0, l] = val\n",
    "    # stream out\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6b580f-74d0-4696-951a-f39a3788df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf(x):\n",
    "  x1 = depthwise(x, conv1_depthwise, 28, 1)\n",
    "  x2 = pointwise(x1, conv1_pointwise, 10, 1, 4)\n",
    "  x3 = depthwise(x2, conv2_depthwise, 10, 4)\n",
    "  x4 = pointwise(x3, conv2_pointwise, 4, 4, 12)\n",
    "  x5 = depthwise_final(x4, conv3_depthwise, 4, 12)\n",
    "  x6 = pointwise(x5, conv3_pointwise, 1, 12, 10)\n",
    "  return x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3ac5636-be76-45a9-9310-970fd1a21c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "Total elapsed time: 477.6563947200775 s\n",
      "Elapsed time per picture: 466.4613229688257 ms\n",
      "Accuracy: tensor(0.9053)\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "total_num = 0\n",
    "import time\n",
    "t0 = time.time()\n",
    "for image, label in zip(images_t, labels):\n",
    "  res = inf(image)\n",
    "  pred = torch.argmax(res)\n",
    "  total_correct += (pred == label)\n",
    "  total_num += 1\n",
    "  if total_num % 100 == 0:\n",
    "    print(total_num)\n",
    "t1 = time.time()\n",
    "print(\"Total elapsed time:\", t1-t0, \"s\")\n",
    "print(\"Elapsed time per picture:\", ((t1-t0) / total_num) * 1000, \"ms\")\n",
    "print('Accuracy:', total_correct / float(total_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d69139-edef-4344-9aff-f16a2342ec66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
